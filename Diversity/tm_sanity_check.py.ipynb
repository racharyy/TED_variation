{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cmath\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "def load_embedding_dict(path_to_glove_file):\n",
    "  embedding_dict = {}\n",
    "  with open(path_to_glove_file, 'r') as f:\n",
    "    for line in f:\n",
    "      val = line.split()\n",
    "      word = val[0]\n",
    "      vector = np.asarray(val[1:], \"float32\")\n",
    "      embedding_dict[word] = vector\n",
    "  return embedding_dict\n",
    "\n",
    "def weighted_vector(input, path):\n",
    "  embedding_dict = load_embedding_dict(path)\n",
    "  return sum(embedding_dict[w]* prob for w,prob in input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = load_embedding_dict('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_vector(input, embedding_dict):\n",
    "  return sum(embedding_dict[w]* prob for w,prob in input if w in embedding_dict)/sum( prob for w,prob in input if w in embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 20\n",
    "NUM_WORDS = 10\n",
    "import pickle\n",
    "with open('topics_dic_'+str(NUM_TOPICS)+'_'+str(NUM_WORDS)+'.pkl','rb') as f:\n",
    "    Input = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('actually', 0.03669041),\n",
       "   ('leaky', 0.036554243),\n",
       "   ('perception', 0.036554243),\n",
       "   ('first', 0.024675718),\n",
       "   ('numerical', 0.024675712),\n",
       "   ('principle', 0.024675712),\n",
       "   ('really', 0.024675703),\n",
       "   ('pound', 0.024675697),\n",
       "   ('psychological', 0.012650636),\n",
       "   ('versus', 0.012638651)]),\n",
       " (1,\n",
       "  [('study', 0.032240335),\n",
       "   ('economics', 0.0295085),\n",
       "   ('shock', 0.021732261),\n",
       "   ('electric', 0.021732261),\n",
       "   ('merely', 0.021732254),\n",
       "   ('would', 0.021732248),\n",
       "   ('people', 0.011150664),\n",
       "   ('random', 0.011131015),\n",
       "   ('nuzzle', 0.011131015),\n",
       "   ('stops', 0.011131015)]),\n",
       " (2,\n",
       "  [('economics', 0.028892929),\n",
       "   ('try', 0.027604291),\n",
       "   ('duration', 0.027579254),\n",
       "   ('think', 0.0145815015),\n",
       "   ('happiness', 0.014138662),\n",
       "   ('silently', 0.014138662),\n",
       "   ('life', 0.01413866),\n",
       "   ('neoclassical', 0.01413866),\n",
       "   ('engineering', 0.01413866),\n",
       "   ('circumstances', 0.01413866)]),\n",
       " (3,\n",
       "  [('something', 0.090621814),\n",
       "   ('thing', 0.037911057),\n",
       "   ('german', 0.03780935),\n",
       "   ('actually', 0.029172862),\n",
       "   ('better', 0.028500952),\n",
       "   ('french', 0.028462341),\n",
       "   ('pound', 0.019179659),\n",
       "   ('study', 0.01917965),\n",
       "   ('bailout', 0.019138565),\n",
       "   ('greece', 0.019138565)]),\n",
       " (4,\n",
       "  [('actually', 0.033979412),\n",
       "   ('warren', 0.01740396),\n",
       "   ('partner', 0.017403958),\n",
       "   ('buffett', 0.017403958),\n",
       "   ('business', 0.017403958),\n",
       "   ('munger', 0.017403957),\n",
       "   ('call', 0.017403957),\n",
       "   ('charlie', 0.017403957),\n",
       "   ('could', 0.017403953),\n",
       "   ('significantly', 0.017403953)]),\n",
       " (5,\n",
       "  [('think', 0.026353203),\n",
       "   ('human', 0.024154963),\n",
       "   ('happiness', 0.024154948),\n",
       "   ('exactly', 0.024154931),\n",
       "   ('mistake', 0.024103083),\n",
       "   ('great', 0.019250734),\n",
       "   ('conditions', 0.012371911),\n",
       "   ('impression', 0.012371911),\n",
       "   ('praxeology', 0.012371911),\n",
       "   ('study', 0.012371911)]),\n",
       " (6,\n",
       "  [('apply', 0.04738047),\n",
       "   ('value', 0.035700675),\n",
       "   ('traffic', 0.035673216),\n",
       "   ('light', 0.035673212),\n",
       "   ('green', 0.023995461),\n",
       "   ('since', 0.02399541),\n",
       "   ('reason', 0.023681255),\n",
       "   ('minutes', 0.01267821),\n",
       "   ('model', 0.012311896),\n",
       "   ('public', 0.012290216)]),\n",
       " (7,\n",
       "  [('think', 0.1155468),\n",
       "   ('actually', 0.06388149),\n",
       "   ('economics', 0.021736199),\n",
       "   ('value', 0.020953914),\n",
       "   ('drive', 0.020104527),\n",
       "   ('money', 0.020104527),\n",
       "   ('psychology', 0.020104526),\n",
       "   ('probably', 0.020086335),\n",
       "   ('right', 0.020086307),\n",
       "   ('great', 0.014379095)]),\n",
       " (8,\n",
       "  [('answer', 0.027638402),\n",
       "   ('would', 0.027638402),\n",
       "   ('change', 0.027638381),\n",
       "   ('train', 0.02763838),\n",
       "   ('ask', 0.02481288),\n",
       "   ('people', 0.01607951),\n",
       "   ('think', 0.014181102),\n",
       "   ('frame', 0.014156118),\n",
       "   ('average', 0.014156116),\n",
       "   ('human', 0.014156116)]),\n",
       " (9,\n",
       "  [('pound', 0.042091213),\n",
       "   ('pill', 0.03157428),\n",
       "   ('white', 0.03157428),\n",
       "   ('change', 0.021305326),\n",
       "   ('reality', 0.021305323),\n",
       "   ('quite', 0.021305319),\n",
       "   ('million', 0.021305319),\n",
       "   ('really', 0.021305317),\n",
       "   ('school', 0.021305315),\n",
       "   ('austrian', 0.021305311)]),\n",
       " (10,\n",
       "  [('small', 0.04008106),\n",
       "   ('google', 0.02693964),\n",
       "   ('marketing', 0.026915189),\n",
       "   ('button', 0.026915189),\n",
       "   ('think', 0.0137982275),\n",
       "   ('deliberately', 0.0137982275),\n",
       "   ('impatience', 0.0137982275),\n",
       "   ('reduce', 0.0137982275),\n",
       "   ('massively', 0.0137982275),\n",
       "   ('irritation', 0.0137982275)]),\n",
       " (11,\n",
       "  [('think', 0.035896536),\n",
       "   ('probably', 0.035852883),\n",
       "   ('pensioner', 0.03536732),\n",
       "   ('engine', 0.024112446),\n",
       "   ('things', 0.024112446),\n",
       "   ('search', 0.024112446),\n",
       "   ('prefer', 0.02409058),\n",
       "   ('overstate', 0.024060726),\n",
       "   ('happy', 0.023604995),\n",
       "   ('value', 0.0123719545)]),\n",
       " (12,\n",
       "  [('really', 0.035421744),\n",
       "   ('stand', 0.035384003),\n",
       "   ('window', 0.035384),\n",
       "   ('stare', 0.035384),\n",
       "   ('decision', 0.02380799),\n",
       "   ('people', 0.023807988),\n",
       "   ('create', 0.023807984),\n",
       "   ('things', 0.023807978),\n",
       "   ('enough', 0.023786077),\n",
       "   ('human', 0.012194198)]),\n",
       " (13,\n",
       "  [('first', 0.08706438),\n",
       "   ('people', 0.08399169),\n",
       "   ('class', 0.06334637),\n",
       "   ('problem', 0.038293898),\n",
       "   ('call', 0.025738444),\n",
       "   ('believe', 0.02571506),\n",
       "   ('arrive', 0.025705392),\n",
       "   ('actually', 0.013182996),\n",
       "   ('solve', 0.013182996),\n",
       "   ('england', 0.013182996)]),\n",
       " (14,\n",
       "  [('value', 0.07615399),\n",
       "   ('create', 0.06669486),\n",
       "   ('thing', 0.048507534),\n",
       "   ('solution', 0.029422779),\n",
       "   ('idea', 0.029422773),\n",
       "   ('economically', 0.019757992),\n",
       "   ('efficient', 0.019757992),\n",
       "   ('pay', 0.019622635),\n",
       "   ('europe', 0.018109616),\n",
       "   ('great', 0.010171317)]),\n",
       " (15,\n",
       "  [('psychological', 0.0684154),\n",
       "   ('money', 0.05715985),\n",
       "   ('example', 0.045284163),\n",
       "   ('think', 0.034590248),\n",
       "   ('people', 0.023215707),\n",
       "   ('train', 0.023215704),\n",
       "   ('going', 0.023215696),\n",
       "   ('great', 0.023194708),\n",
       "   ('solution', 0.02312713),\n",
       "   ('value', 0.0119405445)]),\n",
       " (16,\n",
       "  [('framework', 0.041451823),\n",
       "   ('unemployed', 0.027852725),\n",
       "   ('young', 0.027852725),\n",
       "   ('unemployment', 0.027852632),\n",
       "   ('nearly', 0.02785241),\n",
       "   ('people', 0.017188294),\n",
       "   ('create', 0.0143040335),\n",
       "   ('always', 0.014278823),\n",
       "   ('coming', 0.014278823),\n",
       "   ('things', 0.014278823)]),\n",
       " (17,\n",
       "  [('great', 0.035465445),\n",
       "   ('success', 0.023871737),\n",
       "   ('things', 0.023871735),\n",
       "   ('passenger', 0.023850044),\n",
       "   ('accident', 0.023769053),\n",
       "   ('minutes', 0.020797892),\n",
       "   ('clock', 0.012226859),\n",
       "   ('seven', 0.012226857),\n",
       "   ('train', 0.012226857),\n",
       "   ('countdown', 0.012226856)]),\n",
       " (18,\n",
       "  [('really', 0.030552343),\n",
       "   ('restaurant', 0.030524626),\n",
       "   ('looking', 0.01564864),\n",
       "   ('belief', 0.01564864),\n",
       "   ('depth', 0.01564864),\n",
       "   ('humanity', 0.01564864),\n",
       "   ('spend', 0.015648639),\n",
       "   ('hide', 0.015648639),\n",
       "   ('michelin', 0.015648633),\n",
       "   ('serve', 0.015648633)]),\n",
       " (19,\n",
       "  [('human', 0.04756581),\n",
       "   ('floor', 0.035815656),\n",
       "   ('economist', 0.024087442),\n",
       "   ('money', 0.024087436),\n",
       "   ('psychology', 0.024065653),\n",
       "   ('really', 0.024065653),\n",
       "   ('model', 0.024065651),\n",
       "   ('study', 0.012440478),\n",
       "   ('thing', 0.012359116),\n",
       "   ('action', 0.012337347)])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input[1437]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = {}\n",
    "for idx in Input.keys():\n",
    "    cur_input = Input[idx]\n",
    "    cur_matrix = np.zeros((NUM_TOPICS,300))\n",
    "    for x,y in cur_input:\n",
    "        temp = weighted_vector(y, embedding_dict)\n",
    "        cur_matrix[x,:] = temp/np.linalg.norm(temp)\n",
    "    res1[idx] = cur_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03191324,  0.05020998, -0.03023681, ..., -0.02229455,\n",
       "        -0.00558806,  0.03425717],\n",
       "       [ 0.01086353,  0.04358998, -0.00534921, ...,  0.0093588 ,\n",
       "         0.00811232,  0.06742989],\n",
       "       [ 0.00012421,  0.02205048, -0.03955001, ...,  0.04210504,\n",
       "        -0.01258243,  0.07677636],\n",
       "       ...,\n",
       "       [ 0.0349372 , -0.00797423,  0.03037454, ..., -0.03209136,\n",
       "         0.00668105, -0.01991871],\n",
       "       [ 0.00889267,  0.0370742 , -0.03071335, ...,  0.02926503,\n",
       "        -0.01133661, -0.01252243],\n",
       "       [-0.01317377,  0.0171669 , -0.05224964, ...,  0.01392753,\n",
       "         0.01700716,  0.04778004]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1[1437]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=res1[1810]\n",
    "B = np.dot(A,A.T)\n",
    "print(np.prod(sorted(np.linalg.eigvals(B))[-5:]))\n",
    "#print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_axplained(res):\n",
    "    \n",
    "    lst = np.zeros(NUM_TOPICS)\n",
    "    for k in res.keys():\n",
    "        B = np.dot(res[k],res[k].T)\n",
    "        l=[x.real for x in sorted(np.linalg.eigvals(B))[::-1]]\n",
    "#         print(l)\n",
    "#         break\n",
    "        l1 = []\n",
    "        cur = 0\n",
    "        for x in l:\n",
    "            cur = cur+x\n",
    "            l1.append(cur)\n",
    "            \n",
    "#         print(l1)\n",
    "#         break\n",
    "        l1 = np.array(l1)/l1[-1]\n",
    "        lst = lst+l1\n",
    "    lst = lst/len(list(res.keys()))\n",
    "    print(lst)\n",
    "    plt.plot(range(1,NUM_TOPICS+1),lst)\n",
    "    plt.show()\n",
    "        \n",
    "variance_axplained(res1)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_div(res,k):\n",
    "    div_dic = {}\n",
    "    for key in res.keys():\n",
    "        B = np.dot(res[key],res[key].T)\n",
    "        x = (np.prod(sorted(np.linalg.eigvals(B))[-k:])).real\n",
    "        #print(x,k)\n",
    "        div_dic[key] = x\n",
    "    return div_dic\n",
    "topics_to_keep =5\n",
    "div_dic = create_div(res1,topics_to_keep)\n",
    "pickle.dump(div_dic,open('div_dic.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_ar = list(div_dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(div_ar)\n",
    "plt.hist(div_ar,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/all_features.pkl','rb') as f:\n",
    "    all_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_names = ['beautiful', 'confusing', 'courageous', 'fascinating', 'funny', 'informative', 'ingenious', 'inspiring', 'jaw-dropping', 'longwinded', 'obnoxious', 'ok', 'persuasive', 'unconvincing']\n",
    "pos_ratings_1 = ['beautiful', 'courageous', 'fascinating', 'funny']\n",
    "pos_ratings_2 = ['informative', 'ingenious', 'inspiring', 'jaw-dropping']\n",
    "neg_ratings = ['confusing', 'longwinded', 'obnoxious', 'ok', 'persuasive', 'unconvincing']\n",
    "\n",
    "\n",
    "male_rat_dic = {}\n",
    "for rat in rating_names:\n",
    "    male_rat_dic[rat] = []\n",
    "\n",
    "other_rat_dic = {}\n",
    "for rat in rating_names:\n",
    "    other_rat_dic[rat] = []\n",
    "\n",
    "all_rat_dic = {}\n",
    "for rat in rating_names:\n",
    "    all_rat_dic[rat] = []\n",
    "    \n",
    "male_diversity_ar = [] \n",
    "other_diversity_ar = []\n",
    "all_diversity_ar = []\n",
    "for i in range(all_df.shape[0]):\n",
    "    doc_id = all_df['Video_ID'][i]\n",
    "    divval = div_dic[doc_id]\n",
    "    \n",
    "    if int(all_df['Male'][i]) == 1:\n",
    "        male_diversity_ar.append(divval)\n",
    "        for rat in rating_names:  \n",
    "            rating = float(all_df[rat][i])/float(all_df['total_count'][i])\n",
    "            male_rat_dic[rat].append(rating)\n",
    "    else:\n",
    "        other_diversity_ar.append(divval)\n",
    "        for rat in rating_names:  \n",
    "            rating = float(all_df[rat][i])/float(all_df['total_count'][i])\n",
    "            other_rat_dic[rat].append(rating)\n",
    "            \n",
    "    all_diversity_ar.append(divval)       \n",
    "    for rat in rating_names: \n",
    "        rating = float(all_df[rat][i])/float(all_df['total_count'][i])\n",
    "        all_rat_dic[rat].append(rating)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rat in rating_names:\n",
    "    plt.plot(all_diversity_ar,all_rat_dic[rat],'.',label=rat)\n",
    "    #plt.plot(male_diversity_ar,male_rat_dic[rat],'.',label='male')\n",
    "    #plt.plot(other_diversity_ar,other_rat_dic[rat],'.',label='other')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "plt.savefig('All_scatter.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rat in rating_names:\n",
    "    #plt.plot(all_diversity_ar,all_rat_dic[rat],'.',label='all')\n",
    "    corr_male = str(np.corrcoef(male_diversity_ar,male_rat_dic[rat])[0][1])\n",
    "    corr_other = str(np.corrcoef(other_diversity_ar,other_rat_dic[rat])[0][1])\n",
    "    plt.plot(male_diversity_ar,male_rat_dic[rat],'.',label='male'+corr_male)\n",
    "    plt.plot(other_diversity_ar,other_rat_dic[rat],'.',label='other'+corr_other)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(rat+'.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ol_and_do_binning(dl,rc,num_bin,sigma):\n",
    "    \n",
    "    #creating zipped list and removing outlier\n",
    "    rat_cur = sorted(list(zip(dl,rc)))#[lower_limit:upper_limit]\n",
    "    z = np.abs(stats.zscore(rat_cur))\n",
    "    rat_cur_o = np.array(rat_cur)[(z < sigma).all(axis=1)]\n",
    "   \n",
    "    h,e = np.histogram(rat_cur_o,bins=num_bin)\n",
    "    div, rating = list(zip(*rat_cur_o))\n",
    "    n = len(div)\n",
    "    min_div, max_div = min(div), max(div)\n",
    "    div_ar, rating_ar = [[] for x in range(num_bin)], [[] for x in range(num_bin)]\n",
    "    division = np.linspace(min_div,max_div,num_bin)\n",
    "    cur_next = 1\n",
    "    for i in range(n):\n",
    "        if div[i] <= division[cur_next]:\n",
    "            div_ar[cur_next-1].append(div[i])\n",
    "            rating_ar[cur_next-1].append(rating[i])\n",
    "        else:\n",
    "            cur_next = cur_next+1\n",
    "    #print(div_ar)\n",
    "    new_div_ar, new_rating_ar = [], []\n",
    "    for k in range(num_bin):\n",
    "        if div_ar[k] and rating_ar[k]:\n",
    "            new_div_ar.append(np.array(div_ar[k]))\n",
    "            new_rating_ar.append(np.array(rating_ar[k]))\n",
    "    #div_ar, rating_ar = [np.array(divs) for divs in div_ar], [np.array(rates) for rates in rating_ar]\n",
    "    mean_divs, mean_rates, std_divs, std_rates = [divs.mean() for divs in new_div_ar], [rates.mean() for rates in new_rating_ar], [divs.std() for divs in new_div_ar], [rates.std() for rates in new_rating_ar]\n",
    "    return np.array(mean_divs), np.array(mean_rates), np.array(std_divs), np.array(std_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol(coeff,x):\n",
    "    ans = 0\n",
    "    n= len(coeff)-1\n",
    "    for i,c in enumerate(coeff):\n",
    "        ans = ans + c* x**(n-i)\n",
    "    return ans\n",
    "\n",
    "def polyfit(mean_divs,mean_rates,deg):\n",
    "    coeffs = np.polyfit(mean_divs, mean_rates, deg)\n",
    "    predicted = [pol(coeffs,x) for x in mean_divs]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bin,sigma = 7, 3\n",
    "for rat in rating_names:\n",
    "    all_mean_divs, all_mean_rates = remove_ol_and_do_binning(all_diversity_ar,all_rat_dic[rat],num_bin,sigma)\n",
    "    male_mean_divs, male_mean_rates = remove_ol_and_do_binning(male_diversity_ar,male_rat_dic[rat],num_bin,sigma)\n",
    "    other_mean_divs, other_mean_rates = remove_ol_and_do_binning(other_diversity_ar,other_rat_dic[rat],num_bin,sigma)\n",
    "    \n",
    "    \n",
    "#     plt.plot(all_mean_divs,all_mean_rates,'-*',label='all')\n",
    "    plt.plot(male_mean_divs,male_mean_rates,'-.',label='male')\n",
    "    plt.plot(other_mean_divs,other_mean_rates,'-^',label='other')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(rat+'.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bin,sigma = 7, 3\n",
    "for rat in rating_names:\n",
    "    all_mean_divs, all_mean_rates = remove_ol_and_do_binning(all_diversity_ar,all_rat_dic[rat],num_bin,sigma)\n",
    "    male_mean_divs, male_mean_rates = remove_ol_and_do_binning(male_diversity_ar,male_rat_dic[rat],num_bin,sigma)\n",
    "    other_mean_divs, other_mean_rates = remove_ol_and_do_binning(other_diversity_ar,other_rat_dic[rat],num_bin,sigma)\n",
    "    \n",
    "    \n",
    "    plt.plot(all_mean_divs,all_mean_rates,'-*',label=rat)\n",
    "#     plt.plot(male_mean_divs,male_mean_rates,'-.',label='male')\n",
    "#     plt.plot(other_mean_divs,other_mean_rates,'-^',label='other')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "plt.savefig('All.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bin,sigma = 7, 3\n",
    "deg = 2\n",
    "fig_pos1, axs_pos1 = plt.subplots(2, 2)\n",
    "fig_pos2, axs_pos2 = plt.subplots(2, 2)\n",
    "fig_neg, axs_neg = plt.subplots(2, 3)\n",
    "pos1_ind,pos2_ind,neg_ind = 0,0,0\n",
    "for rat_ind,rat in enumerate(rating_names):\n",
    "    #print(rat_ind)\n",
    "    all_mean_divs, all_mean_rates,_,_ = remove_ol_and_do_binning(all_diversity_ar,all_rat_dic[rat],num_bin,sigma)\n",
    "    male_mean_divs, male_mean_rates,_,_ = remove_ol_and_do_binning(male_diversity_ar,male_rat_dic[rat],num_bin,sigma)\n",
    "    other_mean_divs, other_mean_rates,_,_ = remove_ol_and_do_binning(other_diversity_ar,other_rat_dic[rat],num_bin,sigma)\n",
    "    \n",
    "    if rat in pos_ratings_1:\n",
    "        ax = axs_pos1[int(pos1_ind/2)][int(pos1_ind%2)] \n",
    "        if pos1_ind == 0:\n",
    "            label_all, label_male, label_other = 'all', 'male', 'other'\n",
    "        else:\n",
    "            label_all, label_male, label_other = None, None, None\n",
    "            \n",
    "        ax.plot(all_mean_divs,all_mean_rates,'-*',label=label_all)\n",
    "        ax.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg) )\n",
    "        #ax.plot(male_mean_divs,male_mean_rates,'-.',label=label_male)\n",
    "        #ax.plot(other_mean_divs,other_mean_rates,'-^',label=label_other)\n",
    "        ax.set_title(rat)\n",
    "        pos1_ind = pos1_ind+1\n",
    "        \n",
    "    elif rat in pos_ratings_2:\n",
    "        ax = axs_pos2[int(pos2_ind/2)][int(pos2_ind%2)] \n",
    "        if pos2_ind == 0:\n",
    "            label_all, label_male, label_other = 'all', 'male', 'other'\n",
    "        else:\n",
    "            label_all, label_male, label_other = None, None, None\n",
    "            \n",
    "        ax.plot(all_mean_divs,all_mean_rates,'-*',label=label_all)\n",
    "        ax.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg) )\n",
    "        #ax.plot(male_mean_divs,male_mean_rates,'-.',label=label_male)\n",
    "        #ax.plot(other_mean_divs,other_mean_rates,'-^',label=label_other)\n",
    "        ax.set_title(rat)\n",
    "        pos2_ind = pos2_ind+1\n",
    "        \n",
    "    else:\n",
    "        ax = axs_neg[int(neg_ind/3)][int(neg_ind%3)] \n",
    "        if neg_ind == 0:\n",
    "            label_all, label_male, label_other = 'all', 'male', 'other'\n",
    "        else:\n",
    "            label_all, label_male, label_other = None, None, None\n",
    "            \n",
    "        ax.plot(all_mean_divs,all_mean_rates,'-*',label=label_all)\n",
    "        ax.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg) )\n",
    "        #ax.plot(male_mean_divs,male_mean_rates,'-.',label=label_male)\n",
    "        #ax.plot(other_mean_divs,other_mean_rates,'-^',label=label_other)\n",
    "        ax.set_title(rat)\n",
    "        neg_ind = neg_ind+1\n",
    "fig_pos1.legend()  \n",
    "fig_pos2.legend()\n",
    "fig_neg.legend()  \n",
    "for ax in axs_pos1.flat:\n",
    "    ax.label_outer()    \n",
    "for ax in axs_pos2.flat:\n",
    "    ax.label_outer() \n",
    "for ax in axs_neg.flat:\n",
    "    ax.label_outer() \n",
    "fig_pos1.savefig('Positive1.pdf')\n",
    "fig_pos2.savefig('Positive2.pdf')\n",
    "fig_neg.savefig('Negative.pdf')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bin,sigma = 10, 3\n",
    "fig_pos, axs_pos = plt.subplots(3, 3)\n",
    "fig_neg, axs_neg = plt.subplots(2, 3)\n",
    "pos_ind,neg_ind = 0,0\n",
    "for rat_ind,rat in enumerate(rating_names):\n",
    "    #print(rat_ind)\n",
    "    all_mean_divs, all_mean_rates,_,_ = remove_ol_and_do_binning(all_diversity_ar,all_rat_dic[rat],num_bin,sigma)\n",
    "    male_mean_divs, male_mean_rates,_,_ = remove_ol_and_do_binning(male_diversity_ar,male_rat_dic[rat],num_bin,sigma)\n",
    "    other_mean_divs, other_mean_rates,_,_ = remove_ol_and_do_binning(other_diversity_ar,other_rat_dic[rat],num_bin,sigma)\n",
    "    \n",
    "    if rat in pos_ratings_1 or rat in pos_ratings_2:\n",
    "        ax = axs_pos[int(pos_ind/3)][int(pos_ind%3)] \n",
    "        if pos_ind == 0:\n",
    "            label_all, label_male, label_other = 'all', 'male', 'other'\n",
    "        else:\n",
    "            label_all, label_male, label_other = None, None, None\n",
    "            \n",
    "#         ax.plot(all_mean_divs,all_mean_rates,'-*',label=label_all)\n",
    "        ax.plot(male_mean_divs,male_mean_rates,'-.',label=label_male)\n",
    "        ax.plot(other_mean_divs,other_mean_rates,'-^',label=label_other)\n",
    "        ax.set_title(rat)\n",
    "        pos_ind = pos_ind+1\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        ax = axs_neg[int(neg_ind/3)][int(neg_ind%3)] \n",
    "        if neg_ind == 0:\n",
    "            label_all, label_male, label_other = 'all', 'male', 'other'\n",
    "        else:\n",
    "            label_all, label_male, label_other = None, None, None\n",
    "            \n",
    "#         ax.plot(all_mean_divs,all_mean_rates,'-*',label=label_all)\n",
    "        ax.plot(male_mean_divs,male_mean_rates,'-.',label=label_male)\n",
    "        ax.plot(other_mean_divs,other_mean_rates,'-^',label=label_other)\n",
    "        ax.set_title(rat)\n",
    "        neg_ind = neg_ind+1\n",
    "fig_pos.legend()  \n",
    "fig_neg.legend()  \n",
    "for ax in axs_pos.flat:\n",
    "    ax.label_outer()    \n",
    "for ax in axs_neg.flat:\n",
    "    ax.label_outer() \n",
    "fig_pos.savefig('Positive.pdf')\n",
    "fig_neg.savefig('Negative.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_curve_and_fit_all(rat_name,num_bin,sigma,deg):\n",
    "    \n",
    "    all_mean_divs, all_mean_rates,_,_ = remove_ol_and_do_binning(all_diversity_ar,all_rat_dic[rat_name],num_bin,sigma)\n",
    "    plt.plot(all_mean_divs, all_mean_rates,'-.',label='True')\n",
    "    plt.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg),'-^',label='fitted')\n",
    "    plt.legend()\n",
    "    plt.savefig('Plots/'+rat_name+'_fitted.pdf')\n",
    "    plt.close()\n",
    "sigma, deg = 3, 2    \n",
    "rating_bin_pair = [('beautiful',7), ('confusing',8), ('courageous',7), ('fascinating',7), ('funny',7), ('informative',7), ('ingenious',6), ('inspiring',8), ('jaw-dropping',6), ('longwinded',7), ('obnoxious',8), ('ok',7), ('persuasive',7), ('unconvincing',6)]\n",
    "for rat_name,num_bin in rating_bin_pair:\n",
    "    plot_curve_and_fit_all(rat_name,num_bin,sigma,deg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve_and_fit_all_errorband(rat_name,num_bin,sigma,deg,epsilon):\n",
    "    \n",
    "    all_mean_divs, all_mean_rates, all_std_divs, all_std_rates = remove_ol_and_do_binning(all_diversity_ar,all_rat_dic[rat_name],num_bin,sigma)\n",
    "    plt.plot(all_mean_divs, all_mean_rates,'-.',label='Mean')\n",
    "    error = epsilon*all_std_rates\n",
    "    plt.fill_between(all_mean_divs, all_mean_rates-error,all_mean_rates+error,facecolor='aqua')\n",
    "    #plt.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg),'-^',label='fitted')\n",
    "    plt.xlabel('Variation Metric')\n",
    "    plt.ylabel('Rating')\n",
    "    plt.title(rat_name)\n",
    "    plt.legend()\n",
    "    plt.savefig('Plots/Errorband/'+rat_name+'_errorband.pdf')\n",
    "    plt.close()\n",
    "sigma, deg, epsilon = 3, 2, 0.03    \n",
    "rating_bin_pair = [('beautiful',7), ('confusing',8), ('courageous',7), ('fascinating',7), ('funny',7), ('informative',7), ('ingenious',6), ('inspiring',8), ('jaw-dropping',6), ('longwinded',7), ('obnoxious',8), ('ok',7), ('persuasive',7), ('unconvincing',8)]\n",
    "for rat_name,num_bin in rating_bin_pair:\n",
    "    plot_curve_and_fit_all_errorband(rat_name,num_bin,sigma,deg,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve_multimodal_errorband(text_div_ar,text_rat_dic,audio_div_ar,audio_rat_dic,visual_div_ar,visual_rat_dic,rat_name,num_bin,sigma,deg,epsilon):\n",
    "    \n",
    "    text_mean_divs, text_mean_rates, text_std_divs, text_std_rates = remove_ol_and_do_binning(text_div_ar,text_rat_dic[rat_name],num_bin,sigma)\n",
    "    audio_mean_divs, audio_mean_rates, audio_std_divs, audio_std_rates = remove_ol_and_do_binning(audio_div_ar,audio_rat_dic[rat_name],num_bin,sigma)\n",
    "    visual_mean_divs, visual_mean_rates, visual_std_divs, visual_std_rates = remove_ol_and_do_binning(visual_div_ar,visual_rat_dic[rat_name],num_bin,sigma)\n",
    "    \n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(text_mean_divs, text_mean_rates,'-.',label='Text Mean')\n",
    "    error = epsilon*text_std_rates\n",
    "    plt.fill_between(text_mean_divs, text_mean_rates-error,text_mean_rates+error,facecolor='aqua')\n",
    "    #plt.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg),'-^',label='fitted')\n",
    "    plt.xlabel('Variation Metric')\n",
    "    plt.ylabel('Rating')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(audio_mean_divs, audio_mean_rates,'-*',label='Audio Mean')\n",
    "    error = epsilon*audio_std_rates\n",
    "    plt.fill_between(audio_mean_divs, audio_mean_rates-error,audio_mean_rates+error,facecolor='gold')\n",
    "    #plt.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg),'-^',label='fitted')\n",
    "    plt.xlabel('Variation Metric')\n",
    "    #plt.ylabel('Rating')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(visual_mean_divs, visual_mean_rates,'-^',label='Visual Mean')\n",
    "    error = epsilon*visual_std_rates\n",
    "    plt.fill_between(visual_mean_divs, visual_mean_rates-error,visual_mean_rates+error,facecolor='salmon')\n",
    "    #plt.plot(all_mean_divs,polyfit(all_mean_divs,all_mean_rates,deg),'-^',label='fitted')\n",
    "    plt.xlabel('Variation Metric')\n",
    "    #plt.ylabel('Rating')\n",
    "    \n",
    "    \n",
    "    plt.title(rat_name)\n",
    "    plt.legend()\n",
    "    plt.savefig('Plots/Errorband/'+rat_name+'_multimodal_errorband.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
